{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c524fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (7.3.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\shiva\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55587e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'king':\n",
      "[-0.00010563  0.00053871 -0.00033761 -0.00957101  0.0086268  -0.00434384\n",
      "  0.00420708  0.00133305  0.01193935 -0.01368476 -0.01363142 -0.00895252\n",
      "  0.01887166 -0.00318377 -0.01885848 -0.00109008 -0.00889785  0.01200016\n",
      " -0.01916737  0.005718   -0.01850566  0.0024996   0.0119984   0.0147947\n",
      " -0.01524293 -0.01210605 -0.01367688 -0.01583668 -0.01899816 -0.00425099\n",
      " -0.00167187 -0.0145124   0.01357407  0.00223924  0.01165773  0.00294573\n",
      "  0.00157873 -0.01473626 -0.00435332  0.00864216 -0.01017063  0.00226158\n",
      "  0.00576673 -0.00307272  0.01986459  0.01669927  0.00483133  0.01423649\n",
      "  0.01178288 -0.01116123]\n",
      "\n",
      "Words most similar to 'king':\n",
      "[('paris', 0.2705078721046448), ('france', 0.20483413338661194), ('rome', 0.16624975204467773), ('cat', 0.16492940485477448), ('animal', 0.06961806863546371), ('bus', 0.060982946306467056), ('apple', 0.054855599999427795), ('italy', 0.050771307200193405), ('fruit', 0.04979120194911957), ('dog', 0.0489233136177063)]\n",
      "\n",
      "Analogy result (king - man + woman):\n",
      "[('paris', 0.31318044662475586), ('bus', 0.22229208052158356), ('apple', 0.20037458837032318), ('banana', 0.15472842752933502), ('queen', 0.14168761670589447), ('rome', 0.13882207870483398), ('france', 0.10370468348264694), ('italy', 0.09039351344108582), ('animal', 0.06770189851522446), ('dog', 0.058274149894714355)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Sample corpus (tiny example, usually you'd use millions of sentences)\n",
    "sentences = [\n",
    "    [\"king\", \"queen\", \"man\", \"woman\"],\n",
    "    [\"paris\", \"france\", \"rome\", \"italy\"],\n",
    "    [\"dog\", \"cat\", \"animal\"],\n",
    "    [\"car\", \"bus\", \"train\", \"transport\"],\n",
    "    [\"apple\", \"banana\", \"fruit\"],\n",
    "]\n",
    "\n",
    "# Train a Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, sg=1)\n",
    "\n",
    "# Get the vector for a word\n",
    "print(\"Vector for 'king':\")\n",
    "print(model.wv['king'])\n",
    "\n",
    "# Find most similar words\n",
    "print(\"\\nWords most similar to 'king':\")\n",
    "print(model.wv.most_similar('king'))\n",
    "\n",
    "# Analogy example: king - man + woman â‰ˆ ?\n",
    "result = model.wv.most_similar(positive=['king','woman'], negative=['man'])\n",
    "print(\"\\nAnalogy result (king - man + woman):\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b16716",
   "metadata": {},
   "source": [
    "But the results look a bit strange â€” e.g.,\n",
    "\n",
    "Most similar to \"king\": itâ€™s giving paris, france, rome, catâ€¦ instead of queen.\n",
    "\n",
    "Analogy (king - man + woman): itâ€™s giving paris, bus, appleâ€¦ instead of queen.\n",
    "\n",
    "Why this happens\n",
    "\n",
    "ðŸ‘‰ Because your training corpus is tiny (just a few sentences).\n",
    "Word2Vec learns word relationships only from the text it sees. With such little data:\n",
    "\n",
    "It canâ€™t capture deeper semantics (like \"king ~ queen\").\n",
    "\n",
    "It just finds random co-occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e866de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('system', 0.21617139875888824), ('survey', 0.04468922317028046), ('interface', 0.015203381888568401), ('time', 0.0019510635174810886), ('trees', -0.03284316882491112), ('human', -0.07424270361661911), ('response', -0.09324456751346588), ('graph', -0.09575342386960983), ('eps', -0.10513808578252792), ('user', -0.16909334063529968)]\n"
     ]
    }
   ],
   "source": [
    "# Train on a bigger dataset approach 1\n",
    "\n",
    "# Example: Wikipedia articles, news corpus, or any large text file.\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts  # toy dataset from gensim\n",
    "\n",
    "model = Word2Vec(common_texts, vector_size=100, window=5, min_count=1, sg=1)\n",
    "print(model.wv.most_similar(\"computer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3cd6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 39.7% 660.0/1662.8MB downloaded"
     ]
    },
    {
     "ename": "ContentTooShortError",
     "evalue": "<urlopen error retrieval incomplete: got only 692060160 out of 1743563840 bytes>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mContentTooShortError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapi\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load pretrained Word2Vec (takes a while to download, ~1.5GB)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword2vec-google-news-300\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#C:\\Users\\yourname\\gensim-data\\word2vec-google-news-300\\   <-- the file is downlaoded here\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mmost_similar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mmost_similar(positive\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwoman\u001b[39m\u001b[38;5;124m'\u001b[39m], negative\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mman\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\downloader.py:496\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, return_path)\u001b[0m\n\u001b[0;32m    494\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_dir, file_name)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(folder_dir):\n\u001b[1;32m--> 496\u001b[0m     \u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_path:\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gensim\\downloader.py:396\u001b[0m, in \u001b[0;36m_download\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    394\u001b[0m fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{fname}\u001b[39;00m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(fname\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    395\u001b[0m dst_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tmp_dir, fname)\n\u001b[1;32m--> 396\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreporthook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _calculate_md5_checksum(dst_path) \u001b[38;5;241m==\u001b[39m _get_checksum(name):\n\u001b[0;32m    398\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:280\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    277\u001b[0m                 reporthook(blocknum, bs, size)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m read \u001b[38;5;241m<\u001b[39m size:\n\u001b[1;32m--> 280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentTooShortError(\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval incomplete: got only \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m bytes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;241m%\u001b[39m (read, size), result)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mContentTooShortError\u001b[0m: <urlopen error retrieval incomplete: got only 692060160 out of 1743563840 bytes>"
     ]
    }
   ],
   "source": [
    "# Google released a famous model trained on Google News (100B words, 300 dimensions).  --approach 2 \n",
    "\n",
    "# You can download it and use directly:\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pretrained Word2Vec (takes a while to download, ~1.5GB)\n",
    "model = api.load(\"word2vec-google-news-300\") #C:\\Users\\yourname\\gensim-data\\word2vec-google-news-300\\   <-- the file is downlaoded here\n",
    "\n",
    "print(model.most_similar(\"king\"))\n",
    "print(model.most_similar(positive=['king','woman'], negative=['man']))\n",
    "\n",
    "\n",
    "# Output will be much better:\n",
    "\n",
    "# Most similar to 'king': [('prince', 0.71), ('queen', 0.69), ...]\n",
    "# Analogy: king - man + woman â‰ˆ queen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
